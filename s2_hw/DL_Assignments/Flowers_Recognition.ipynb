{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXgJ6uT1NydQ"
   },
   "source": [
    "Assignment: Flowers Recognition <br>\n",
    "Dataset Description:<br>\n",
    "\n",
    "This dataset contains 4242 images of flowers.<br>\n",
    "The data collection is based on the data flicr, google images, yandex images.<br>\n",
    "You can use this datastet to recognize plants from the photo.<br>\n",
    "\n",
    "Attribute Information:<br>\n",
    "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
    "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
    "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
    "This is a Multiclass Classification Problem.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy-ktuOKJH"
   },
   "source": [
    "WORKFLOW : <br>\n",
    "Load Data <br>\n",
    "Split into 60 and 40 ratio.<br>\n",
    "Encode labels.<br>\n",
    "Create Model<br>\n",
    "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
    "Train the Model.<br>\n",
    "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
    "Prediction should be > 85%<br>\n",
    "Evaluation Step<br>\n",
    "Prediction<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri3Bg5qfPRic"
   },
   "source": [
    "Data : <br>\n",
    "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n",
      "dandelion\n",
      "flowers\n",
      "rose\n",
      "sunflower\n",
      "tulip\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D,Dense,Dropout,Input,Flatten,MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model,to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing import image\n",
    "p = Path('./flowers')\n",
    "dirs = p.glob('*')\n",
    "image_data = []\n",
    "labels = []\n",
    "label_dict = {'dandelion':0,'daisy':1,'flowers':2,'sunflower':3,'tulip':4,'rose':5}\n",
    "for folder_dir in dirs:\n",
    "    label= str(folder_dir).split('\\\\')[-1]\n",
    "    cnt = 0\n",
    "    print(label)\n",
    "    for image_path in folder_dir.glob('*.jpg'):\n",
    "        img = image.load_img(image_path,target_size = (64,64))\n",
    "        img_array = image.img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "        labels.append(label_dict[label])\n",
    "x = np.array(image_data)\n",
    "y = np.array(labels)\n",
    "num_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1,image_size,image_size,3])\n",
    "x_test = np.reshape(x_test,[-1,image_size,image_size,3])\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64,64,3)\n",
    "inputs = Input(shape = input_shape)\n",
    "x = inputs\n",
    "x = Conv2D(32,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
    "x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "\n",
    "x = Conv2D(64,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
    "x = MaxPooling2D(pool_size = (2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Conv2D(128,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
    "x = Conv2D(256,kernel_size = 2,activation = 'relu',strides = 1,padding = 'same')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(6,activation = 'softmax')(x)\n",
    "flower_classifier = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_classifier.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 22s 935ms/step - loss: 1.6525 - accuracy: 0.2353\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 19s 902ms/step - loss: 1.3286 - accuracy: 0.4357\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 20s 949ms/step - loss: 1.1366 - accuracy: 0.5251\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 19s 900ms/step - loss: 1.1062 - accuracy: 0.5473\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 19s 914ms/step - loss: 1.0538 - accuracy: 0.5630\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 18s 867ms/step - loss: 1.0016 - accuracy: 0.6086\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 18s 866ms/step - loss: 0.9619 - accuracy: 0.6233\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 20s 969ms/step - loss: 0.9300 - accuracy: 0.6251\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 20s 959ms/step - loss: 0.8827 - accuracy: 0.6523\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 21s 987ms/step - loss: 0.7889 - accuracy: 0.7101\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 21s 989ms/step - loss: 0.7590 - accuracy: 0.7112\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 17s 830ms/step - loss: 0.7512 - accuracy: 0.6945\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 17s 825ms/step - loss: 0.6705 - accuracy: 0.7446\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 17s 825ms/step - loss: 0.6255 - accuracy: 0.7640\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 17s 831ms/step - loss: 0.6587 - accuracy: 0.7628\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 17s 820ms/step - loss: 0.5370 - accuracy: 0.8028\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.5585 - accuracy: 0.7752\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 17s 817ms/step - loss: 0.4486 - accuracy: 0.8220\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 17s 823ms/step - loss: 0.4248 - accuracy: 0.8360\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 17s 823ms/step - loss: 0.3923 - accuracy: 0.8685\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 17s 822ms/step - loss: 0.3130 - accuracy: 0.8872\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 17s 830ms/step - loss: 0.3486 - accuracy: 0.8842\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 18s 852ms/step - loss: 0.2602 - accuracy: 0.9018\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 19s 900ms/step - loss: 0.2108 - accuracy: 0.9271\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 18s 850ms/step - loss: 0.2272 - accuracy: 0.9174\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 18s 840ms/step - loss: 0.1920 - accuracy: 0.9384\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 18s 843ms/step - loss: 0.1779 - accuracy: 0.9423\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 17s 829ms/step - loss: 0.2232 - accuracy: 0.9297\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.1377 - accuracy: 0.9508\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.2158 - accuracy: 0.9242\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 18s 861ms/step - loss: 0.1631 - accuracy: 0.9508\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 18s 832ms/step - loss: 0.1279 - accuracy: 0.9624\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.0931 - accuracy: 0.9690\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 17s 824ms/step - loss: 0.0962 - accuracy: 0.9660\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 17s 825ms/step - loss: 0.1063 - accuracy: 0.9637\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 18s 835ms/step - loss: 0.0629 - accuracy: 0.9802\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 18s 860ms/step - loss: 0.0709 - accuracy: 0.9767\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 20s 927ms/step - loss: 0.0494 - accuracy: 0.9884\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 20s 933ms/step - loss: 0.0417 - accuracy: 0.9874\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 19s 926ms/step - loss: 0.1315 - accuracy: 0.9480\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 19s 924ms/step - loss: 0.0982 - accuracy: 0.9679\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 20s 929ms/step - loss: 0.1057 - accuracy: 0.9679\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 20s 937ms/step - loss: 0.0640 - accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 20s 947ms/step - loss: 0.0702 - accuracy: 0.9727\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0664 - accuracy: 0.9786\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 20s 929ms/step - loss: 0.0531 - accuracy: 0.9816\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0496 - accuracy: 0.9823\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 20s 934ms/step - loss: 0.0365 - accuracy: 0.9909\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 19s 927ms/step - loss: 0.0397 - accuracy: 0.9883\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0259 - accuracy: 0.9928\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 20s 936ms/step - loss: 0.0386 - accuracy: 0.9903\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 20s 930ms/step - loss: 0.0318 - accuracy: 0.9909\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 19s 925ms/step - loss: 0.0323 - accuracy: 0.9904\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 18s 839ms/step - loss: 0.0435 - accuracy: 0.9899\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0286 - accuracy: 0.9923\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 17s 822ms/step - loss: 0.0406 - accuracy: 0.9863\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 18s 872ms/step - loss: 0.0299 - accuracy: 0.9917\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 17s 829ms/step - loss: 0.0301 - accuracy: 0.9918\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0494 - accuracy: 0.9829\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 17s 828ms/step - loss: 0.0324 - accuracy: 0.9908\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 17s 828ms/step - loss: 0.0431 - accuracy: 0.9855\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 19s 892ms/step - loss: 0.0310 - accuracy: 0.9890\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 20s 927ms/step - loss: 0.0486 - accuracy: 0.9824\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 19s 927ms/step - loss: 0.0284 - accuracy: 0.9920\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 20s 927ms/step - loss: 0.0353 - accuracy: 0.9896\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0332 - accuracy: 0.9876\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 20s 931ms/step - loss: 0.0371 - accuracy: 0.9896\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 20s 931ms/step - loss: 0.0395 - accuracy: 0.9871\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 19s 926ms/step - loss: 0.0261 - accuracy: 0.9939\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 20s 951ms/step - loss: 0.0263 - accuracy: 0.9938\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 19s 924ms/step - loss: 0.0367 - accuracy: 0.9897\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 20s 933ms/step - loss: 0.0249 - accuracy: 0.9942\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 19s 922ms/step - loss: 0.0210 - accuracy: 0.9938\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 20s 938ms/step - loss: 0.0196 - accuracy: 0.9947\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 20s 940ms/step - loss: 0.0310 - accuracy: 0.9901\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 20s 945ms/step - loss: 0.0287 - accuracy: 0.9890\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 20s 942ms/step - loss: 0.0298 - accuracy: 0.9916\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 18s 872ms/step - loss: 0.0370 - accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.0218 - accuracy: 0.9942\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 18s 837ms/step - loss: 0.0149 - accuracy: 0.9957\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 17s 827ms/step - loss: 0.0126 - accuracy: 0.9972\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 17s 826ms/step - loss: 0.0244 - accuracy: 0.9908\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 17s 825ms/step - loss: 0.0252 - accuracy: 0.9939\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 17s 824ms/step - loss: 0.0238 - accuracy: 0.9928\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 17s 828ms/step - loss: 0.0134 - accuracy: 0.9970\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 17s 830ms/step - loss: 0.0127 - accuracy: 0.9967\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 19s 900ms/step - loss: 0.0159 - accuracy: 0.9964\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 20s 931ms/step - loss: 0.0201 - accuracy: 0.9947\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 20s 925ms/step - loss: 0.0145 - accuracy: 0.9953\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 20s 938ms/step - loss: 0.0269 - accuracy: 0.9931\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 20s 926ms/step - loss: 0.0215 - accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 19s 924ms/step - loss: 0.0262 - accuracy: 0.9905\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0186 - accuracy: 0.9957\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 20s 931ms/step - loss: 0.0235 - accuracy: 0.9936\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 20s 928ms/step - loss: 0.0330 - accuracy: 0.9881\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 20s 932ms/step - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 19s 926ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 20s 929ms/step - loss: 0.0166 - accuracy: 0.9959\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 21s 994ms/step - loss: 0.0199 - accuracy: 0.9944\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 19s 925ms/step - loss: 0.0133 - accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x193c755a220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_classifier.fit(x_train,y_train,batch_size=128,epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0056438e-20, 1.4690729e-16, 3.0351633e-27, 1.8030059e-21,\n",
       "        9.9999988e-01, 1.0805116e-07],\n",
       "       [2.6879348e-15, 9.9999976e-01, 6.5249298e-28, 6.2412475e-08,\n",
       "        6.4695278e-08, 6.8748128e-14],\n",
       "       [1.2253831e-08, 5.2848104e-03, 1.9184188e-12, 6.3873471e-05,\n",
       "        1.1480560e-02, 9.8317069e-01],\n",
       "       ...,\n",
       "       [5.4233387e-09, 7.3840609e-05, 2.6626765e-20, 9.9992609e-01,\n",
       "        4.3439394e-10, 4.7465321e-10],\n",
       "       [1.7000277e-13, 3.9857112e-14, 2.7738930e-31, 1.0000000e+00,\n",
       "        3.3599550e-11, 1.9992994e-26],\n",
       "       [2.1564226e-12, 9.9997652e-01, 3.1711865e-22, 9.3643929e-16,\n",
       "        3.7420591e-07, 2.3139954e-05]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_classifier.evaluate(x_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Flowers Recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
